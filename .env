# Ollama Configuration
OLLAMA_MODEL=llama3.2:3b
OLLAMA_EMBEDDING_MODEL=mxbai-embed-large
OLLAMA_BASE_URL=http://localhost:11434

# ChromaDB Configuration
CHROMA_PERSIST_DIRECTORY=./vectorstore

# Document Processing
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# Enhanced RAG Settings
RELEVANCE_THRESHOLD=0.1        # Minimum similarity score for retrieval
MULTI_QUERY_COUNT=3            # Number of query variations to generate
K_PER_QUERY=3                  # Documents to retrieve per query variation
TOP_K_RESULTS=5                # Final number of documents to use

# LLM Settings
TEMPERATURE=0.3                # Lower = more focused responses
MAX_TOKENS=300                 # Maximum response length